{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Notebook : GloveEmbedding + BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intalling libraries \n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential, load_model\n",
    "from keras import layers\n",
    "from keras.layers import Dense, LSTM, Embedding, Dropout, Bidirectional, Lambda, Flatten\n",
    "from keras.preprocessing.text import Tokenizer \n",
    "import keras\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(108201, 5)\n",
      "MRDA Data :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Utterances</th>\n",
       "      <th>Basic</th>\n",
       "      <th>General</th>\n",
       "      <th>Full</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fe016</td>\n",
       "      <td>so um</td>\n",
       "      <td>F</td>\n",
       "      <td>fh</td>\n",
       "      <td>fh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fe016</td>\n",
       "      <td>i was going to try to get out of here like in ...</td>\n",
       "      <td>S</td>\n",
       "      <td>s</td>\n",
       "      <td>rt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fe016</td>\n",
       "      <td>um</td>\n",
       "      <td>F</td>\n",
       "      <td>fh</td>\n",
       "      <td>fh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fe016</td>\n",
       "      <td>because i really appreciate people coming.</td>\n",
       "      <td>S</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fe016</td>\n",
       "      <td>and the main thing that i was going to ask peo...</td>\n",
       "      <td>S</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fe016</td>\n",
       "      <td>so anything that transcribers or discourse cod...</td>\n",
       "      <td>S</td>\n",
       "      <td>s</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>fe016</td>\n",
       "      <td>so we have this um</td>\n",
       "      <td>D</td>\n",
       "      <td>fh</td>\n",
       "      <td>fh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>fe016</td>\n",
       "      <td>i think a starting point is clearly the the ch...</td>\n",
       "      <td>S</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fe016</td>\n",
       "      <td>which don brought a copy of.</td>\n",
       "      <td>S</td>\n",
       "      <td>s</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>me011</td>\n",
       "      <td>yeah.</td>\n",
       "      <td>B</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Speaker                                         Utterances Basic General  \\\n",
       "0   fe016                                              so um     F      fh   \n",
       "1   fe016  i was going to try to get out of here like in ...     S       s   \n",
       "2   fe016                                                 um     F      fh   \n",
       "3   fe016         because i really appreciate people coming.     S       s   \n",
       "4   fe016  and the main thing that i was going to ask peo...     S       s   \n",
       "5   fe016  so anything that transcribers or discourse cod...     S       s   \n",
       "6   fe016                                 so we have this um     D      fh   \n",
       "7   fe016  i think a starting point is clearly the the ch...     S       s   \n",
       "8   fe016                       which don brought a copy of.     S       s   \n",
       "9   me011                                              yeah.     B       b   \n",
       "\n",
       "  Full  \n",
       "0   fh  \n",
       "1   rt  \n",
       "2   fh  \n",
       "3    s  \n",
       "4    s  \n",
       "5    e  \n",
       "6   fh  \n",
       "7    s  \n",
       "8    e  \n",
       "9    b  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing the MRDA data \n",
    "data = pd.read_csv('../Datasets/MRDA/mrda_data/full_set.txt', sep='|')\n",
    "data.columns=['Speaker','Utterances','Basic','General','Full']\n",
    "print(data.shape)\n",
    "print(\"MRDA Data :\")\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                so um\n",
       "1    i was going to try to get out of here like in ...\n",
       "2                                                   um\n",
       "3            because i really appreciate people coming\n",
       "4    and the main thing that i was going to ask peo...\n",
       "Name: Utterances, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Utterances'] = data['Utterances'].apply(lambda x: x.lower())\n",
    "data['Utterances'] = data['Utterances'].apply(lambda x: re.sub('[^a-zA-z0-9\\s]','',x))\n",
    "data['Utterances'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Label'>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Creating table of number of each data label present in the dataset\n",
    "label_count=data.groupby('Basic')['Basic'].agg('count')\n",
    "label_count.to_numpy(dtype=int)\n",
    "label_count = np.expand_dims(label_count, axis=0)\n",
    "label_count.shape=(5,1)\n",
    "labels=np.array(['B', 'D', 'F', 'Q', 'S'])\n",
    "labels.shape=(5,1)\n",
    "label_count=np.column_stack((labels,label_count))\n",
    "\n",
    "df = pd.DataFrame(label_count, columns=['Label', 'Count'])\n",
    "\n",
    "convert_dict = {'Label': str,\n",
    "                'Count': int\n",
    "               }\n",
    "  \n",
    "df = df.astype(convert_dict)\n",
    "# labels statistics,it seems like we have balanced data, since statement are the ones that are naturally the most used in a conversation\n",
    "df.plot.bar(x = 'Label', y='Count', color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(108201, 77)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 11,  16,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  2,  36,  59,   4, 168,   4,  61,  81,  10,  97,  35,  15, 438,\n",
       "         86, 659,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tokenizing the words and padding the sentence\n",
    "MAX_PADDING = 77\n",
    "tokenizer = Tokenizer(num_words = 5000, split=\" \")\n",
    "tokenizer.fit_on_texts(data['Utterances'].values)\n",
    "x_train = tokenizer.texts_to_sequences(data['Utterances'].values)\n",
    "x_train = pad_sequences(x_train, padding='post', maxlen=MAX_PADDING)\n",
    "print(x_train.shape)\n",
    "x_train[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F [0 0 1 0 0]\n",
      "S [0 0 0 0 1]\n",
      "F [0 0 1 0 0]\n",
      "S [0 0 0 0 1]\n",
      "S [0 0 0 0 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = pd.get_dummies(data['Basic']).values\n",
    "[print(data['Basic'][i],y_train[i]) for i in range (0,5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Glove Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "f = open(\"../glove.6B/glove.6B.300d.txt\",  encoding=\"utf8\")  # using the Glove Embedding, see article for more explanation \n",
    "embedd_index = {}\n",
    "for line in f:\n",
    "    val = line.split()\n",
    "    word = val[0]\n",
    "    coff = np.asarray(val[1:],dtype = 'float')\n",
    "    embedd_index[word] = coff\n",
    "\n",
    "f.close()\n",
    "print('Found %s word vectors.' % len(embedd_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.3602e-01, -1.1594e-01, -1.7078e-02, -2.9256e-01,  1.6149e-02,\n",
       "        8.6472e-02,  1.5759e-03,  3.4395e-01,  2.1661e-01, -2.1366e+00,\n",
       "        3.5278e-01, -2.3909e-01, -2.2174e-01,  3.6413e-01, -4.5021e-01,\n",
       "        1.2104e-01, -1.5596e-01, -3.8906e-02, -2.9419e-03,  1.6009e-02,\n",
       "       -1.1620e-01,  3.8680e-01,  3.5109e-01,  9.7426e-02, -1.2425e-02,\n",
       "       -1.7864e-01, -2.3259e-01, -2.6960e-01,  4.1083e-02, -7.6194e-02,\n",
       "       -2.3362e-01,  2.0919e-01, -2.7264e-01,  5.4967e-02, -1.8055e+00,\n",
       "        5.6348e-01, -1.2778e-01,  2.3147e-01, -5.8820e-03, -2.6630e-01,\n",
       "        4.1187e-01, -3.7162e-01, -2.0600e-01, -1.9619e-01, -4.3945e-03,\n",
       "        1.2513e-01,  4.6638e-01,  4.5159e-01, -1.5000e-01,  5.9589e-03,\n",
       "        5.9070e-02, -4.1440e-01,  6.1035e-02, -2.1117e-01, -4.0988e-01,\n",
       "        5.6393e-01,  2.3021e-01,  2.7240e-01,  4.9364e-02,  1.4239e-01,\n",
       "        4.1841e-01, -1.3983e-01,  3.4826e-01, -1.0745e-01, -2.5002e-01,\n",
       "       -3.2554e-01,  3.3343e-01, -3.5617e-01,  2.0442e-01,  1.4439e-01,\n",
       "       -1.2686e-01, -7.7273e-02, -1.9667e-01,  1.0759e-01, -1.1860e-01,\n",
       "       -2.5083e-01,  1.4205e-02,  2.7251e-01, -2.3707e-01, -2.3545e-01,\n",
       "       -1.5887e-01,  1.3151e-01,  6.9564e-01,  2.2766e-01,  1.8526e-01,\n",
       "        1.5743e-01, -1.5018e-01, -1.8177e-01, -3.3527e-02, -3.3092e-01,\n",
       "       -2.5205e-01,  5.0913e-01, -2.5607e-01, -5.3686e-01,  1.3397e-01,\n",
       "        6.7046e-02, -9.4473e-02, -2.2270e-01, -3.1469e-01,  8.5932e-02,\n",
       "       -4.3032e-02, -2.5821e-01, -9.5062e-02, -1.8497e-01,  5.8890e-02,\n",
       "        1.8972e-01, -1.7366e-01,  2.5263e-01, -5.4361e-01, -3.7248e-01,\n",
       "       -4.6661e-02, -4.1657e-01, -1.7549e-03, -4.8404e-01,  4.2090e-01,\n",
       "       -1.2749e-03,  9.4697e-03, -1.3380e-01,  7.2351e-02, -1.2096e-01,\n",
       "       -7.2870e-02, -1.8333e-01,  3.9652e-01,  1.1329e-01, -6.3029e-02,\n",
       "       -1.9702e-03,  4.2848e-01,  3.1790e-01, -1.5079e-01,  2.0405e-01,\n",
       "        2.1828e-01,  2.6067e-02,  4.3621e-02,  3.9224e-03, -2.6629e-01,\n",
       "       -2.8312e-01,  5.0497e-02, -1.8993e-01,  1.8996e-01,  2.9517e-01,\n",
       "       -1.1566e-01,  4.0967e-01,  2.2221e-01, -3.9778e-01, -3.3177e-01,\n",
       "       -1.3884e-01, -1.6829e-01, -2.0355e-01, -2.7687e-01, -1.1087e-01,\n",
       "       -6.7466e-01, -1.8108e-01,  1.8512e-01, -9.4616e-02,  1.7856e-01,\n",
       "       -6.6997e-02,  1.1379e-01, -9.3380e-02,  5.6860e-01, -1.3365e-01,\n",
       "        3.4636e-01, -4.1953e-01,  1.7547e-01, -2.4277e-02, -1.2441e-01,\n",
       "        9.2129e-02, -1.6702e-01, -1.4285e-01,  3.1646e-01,  3.0337e-01,\n",
       "        1.4840e-01, -6.7837e-03, -1.0509e+00,  2.2329e-01,  7.5211e-02,\n",
       "        4.4379e-02, -8.5929e-02, -1.1806e-01, -1.6632e-01, -7.8650e-02,\n",
       "        2.6374e-01, -2.2052e-01,  4.5582e-01, -1.5291e-01,  6.2617e-02,\n",
       "       -1.5588e-01,  8.2398e-02, -6.8462e-02, -2.4569e-01,  2.3439e-01,\n",
       "       -3.8633e-01,  2.4835e-01,  2.5334e-01, -2.1189e-01,  4.1494e-03,\n",
       "       -4.3762e-01, -1.3426e-01, -2.4583e-01,  1.4213e-01, -3.3973e-01,\n",
       "        1.4643e+00,  1.6414e-01,  2.2135e-01,  7.4099e-03, -5.5141e-02,\n",
       "       -2.7403e-02,  3.2928e-02,  1.4289e-01, -1.0049e-01, -2.2066e-01,\n",
       "       -3.0380e-01,  6.0624e-02, -1.2408e-01, -5.4114e-01,  2.4374e-01,\n",
       "        8.0903e-02, -7.8264e-02,  8.0091e-02,  9.8551e-03, -2.3077e-01,\n",
       "        1.6006e-01,  6.4075e-02, -4.1613e-01,  2.0494e-01, -1.8681e-01,\n",
       "        3.5367e-02,  2.1759e-01, -8.7823e-02,  3.5452e-01,  1.9578e-01,\n",
       "       -1.5127e-01, -1.0545e-01,  3.5650e-01, -3.8677e-01, -6.3172e-02,\n",
       "        3.1534e-01, -1.5887e-01, -3.1267e-01, -1.7893e-01,  4.1952e-01,\n",
       "        2.3261e-01,  2.0943e-01,  2.7013e-02,  1.7388e-02, -5.9857e-01,\n",
       "       -1.9622e-01, -2.3672e-01,  3.0032e-01,  4.6926e-02, -8.5768e-02,\n",
       "        3.6539e-01, -5.2476e-01, -1.3618e-01,  1.0868e-01,  4.6307e-01,\n",
       "        3.8502e-01,  7.6317e-04, -3.8196e-01,  7.9772e-02, -4.1744e-02,\n",
       "        4.7625e-02, -4.1018e-02,  1.7601e-01,  2.4893e-01, -1.0753e-01,\n",
       "        3.1935e-01, -1.2762e-01, -3.5059e-01,  3.5689e-04,  9.3515e-03,\n",
       "       -8.8616e-02, -3.2785e-01,  9.2063e-02, -6.1405e-02,  2.9053e-01,\n",
       "        2.2404e-02, -1.6879e+00,  2.6712e-01,  3.3419e-01, -5.2533e-02,\n",
       "       -1.9741e-01,  1.3709e-01, -5.4288e-02,  5.6423e-01,  1.9384e-01,\n",
       "        1.7229e-01,  2.9025e-01, -1.6124e-01,  5.9489e-02, -3.1884e-01,\n",
       "       -2.8343e-01,  6.4321e-02, -4.1589e-01, -7.0528e-02,  1.2410e-02,\n",
       "       -4.0208e-01, -2.4963e-01, -3.3760e-01,  7.0098e-02,  2.4642e-01])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedd_index['good']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11113\n"
     ]
    }
   ],
   "source": [
    "index_of_words = tokenizer.word_index\n",
    "print(len(index_of_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11114, 300)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix = np.zeros((len(index_of_words) + 1, 300))\n",
    "\n",
    "tokens = []\n",
    "labels = []\n",
    "\n",
    "for word,i in index_of_words.items():\n",
    "    temp = embedd_index.get(word)\n",
    "    if temp is not None:\n",
    "        embedding_matrix[i] = temp\n",
    "        \n",
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling & Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedd_layer = Embedding(input_dim=len(index_of_words) + 1 , \n",
    "                         output_dim=300 , \n",
    "                         input_length = 77 , \n",
    "                         weights = [embedding_matrix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 77)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 77, 300)      3334200     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 77, 256)      439296      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 77, 1)        257         bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 77)           0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 77)           0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector (RepeatVector)    (None, 256, 77)      0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "permute (Permute)               (None, 77, 256)      0           repeat_vector[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply (Multiply)             (None, 77, 256)      0           bidirectional[0][0]              \n",
      "                                                                 permute[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 256)          0           multiply[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 5)            1285        lambda[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 3,775,038\n",
      "Trainable params: 3,775,038\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "MAX_LENGTH_PER_SENTENCE=77\n",
    "units = 128\n",
    "encoder_input = keras.Input(shape=(MAX_LENGTH_PER_SENTENCE))\n",
    "x = layers.Embedding(input_dim=len(index_of_words) + 1 , \n",
    "                     output_dim=300 , \n",
    "                     input_length = 77 , \n",
    "                     weights = [embedding_matrix])(encoder_input)\n",
    "                              \n",
    "activations = layers.Bidirectional(layers.LSTM(units, \n",
    "                                               dropout=0.3, \n",
    "                                               recurrent_dropout=0.2,\n",
    "                                               return_sequences=True))(x)    # the use of BiLSTM\n",
    "\n",
    "attention = layers.Dense(1, activation='tanh')(activations)\n",
    "attention = layers.Flatten()(attention)\n",
    "attention = layers.Activation('softmax')(attention)\n",
    "attention = layers.RepeatVector(units*2)(attention)\n",
    "attention = layers.Permute((2, 1))(attention)\n",
    "\n",
    "sent_representation = layers.Multiply()([activations, attention])\n",
    "sent_representation = layers.Lambda(lambda X: K.sum(X, axis=-2), output_shape=(units*2,))(sent_representation)\n",
    "\n",
    "\n",
    "probabilities = layers.Dense(5, activation='softmax')(sent_representation)\n",
    "\n",
    "\n",
    "encoder = keras.Model(inputs=[encoder_input], outputs=[probabilities],name='encoder')\n",
    "\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Early stopping the training when accuracy decreases\n",
    "es = keras.callbacks.EarlyStopping(monitor='accuracy', mode='auto', patience=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3382/3382 [==============================] - 2458s 726ms/step - loss: 0.5044 - accuracy: 0.8093\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x27ce77a7610>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.fit(x_train, y_train, epochs=1, batch_size=32, callbacks=[es], verbose=1)   # one epochs because of computational resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S [0 0 0 0 1]\n",
      "S [0 0 0 0 1]\n",
      "S [0 0 0 0 1]\n",
      "F [0 0 1 0 0]\n",
      "S [0 0 0 0 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test set processing\n",
    "test_set = pd.read_csv('../Datasets/MRDA/mrda_data/test_set.txt', sep='|')\n",
    "test_set.columns=['Speaker','Utterances','Basic','General','Full']\n",
    "test_set['Utterances'] = test_set['Utterances'].apply(lambda x: x.lower())\n",
    "test_set['Utterances'] = test_set['Utterances'].apply(lambda x: re.sub('[^a-zA-z0-9\\s]','',x))\n",
    "\n",
    "tokenizer = Tokenizer(num_words = 5000, split=\" \")\n",
    "tokenizer.fit_on_texts(test_set['Utterances'].values)\n",
    "x_test = tokenizer.texts_to_sequences(test_set['Utterances'].values)\n",
    "x_test = pad_sequences(x_test, padding='post', maxlen=MAX_PADDING)\n",
    "\n",
    "y_test = pd.get_dummies(test_set['Basic']).values\n",
    "[print(test_set['Basic'][i],y_test[i]) for i in range (0,5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "522/522 [==============================] - 59s 105ms/step - loss: 1.9399 - accuracy: 0.5412\n"
     ]
    }
   ],
   "source": [
    "score = encoder.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the model accuracy is then : 0.54\n"
     ]
    }
   ],
   "source": [
    "print('the model accuracy is then : 0.54')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "we didn't get theright prediction, this is logical beacuse the validation accuracy is 0.54. it's better to try other models  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
